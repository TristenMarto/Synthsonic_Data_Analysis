\lhead{Discussion}
The main goal of the thesis is to give a broad view of oversampling performance on a wide variety of highly imbalanced datasets. In doing so, it generalizes the performance leading to the loss of information from individual datasets. As the results have shown, performance between oversamplers is very similar with minor differences in scores. From this perspective, the thesis agrees with the article of Camino et al.~\cite{Camino2020OversamplingEffort}, stating that oversampling offers an improvement, but it is minor compared to the effort it requires. 

The scores achieved with XGBoost were often close to their oversampled versions. In cases were the scores were low, oversampling did not significantly improve it. This leads to the belief that the classifier itself is the key factor to performance, and adding additional samples does not provide the desired effect. The literature agrees with this finding, stating that XGBoost is robust against class imbalance~\cite{Camino2020OversamplingEffort}. It is not clear if this algorithm can benefit from the injection of synthetic samples tot the minority class.

This leads to the next point of oversampling with Synthsonic, as it seems that synthesizing new independent samples do not improve on other SMOTE-based oversamplers. While Synthsonic outperformed others on some datasets, it did not show a significant improvement averaged over all datasets. The hypothesis was that SMOTE-based oversamplers were at risk of overfitting in cases of low sample size. The independent samples generated by Synthsonic would counter this risk and therefore perform better. Based on the results from this thesis, Synthsonic performs best on small datasets with few features and low number of minority samples, with diminishing returns as datasets grow.

With the results showing that oversampling offers a minor improvement, it raises the question why SMOTE oversamplers are so popular in use. Kovacs et al.~\cite{Kovacs2019AnDatasets} listed 85 variants of SMOTE, showing how much time and effort has been put into this topic. This study shows two reasons for this: SMOTE oversamplers are quick, with runtimes under a second, and they are easy to use. Secondly, the results can be improved more by applying undersampling as well. Having said that, the findings of Kovacs et al. differ from the results presented here. The Geometric mean and f1 score for k-nearest neighbours in this thesis are significantly lower than in the study of Kovacs et al. A possible explanation for this lies in the datasets which were used. In Kovacs et al., datasets have a lower IR (meaning the classes are more balanced), datasets are smaller and contain fewer minority samples and have fewer features. These factors can all contribute to the performance difference. However, this study also finds that the relative performance between oversamplers is minor, and the original SMOTE algorithm is capable of good results. Additionally, using a robust classifier such as XGBoost offers a performance increase similar to a simple model with oversampling.  

A final point of discussion is that there were no evident characteristics in the datasets showing that oversampling would be beneficial. The datasets in this study varied in size, imbalance ratio and features, but no clear connection was found between these factors and oversampling. All oversamplers performed equally well, achieving the highest scores on some datasets but being outperformed on others. The only exception that can be made here is SMOTE-NC, which suffers from the limitation that it can't be used on exclusively numerical or exclusively categorical datasets.

In summary, this thesis offers a comparison between SMOTE-based techniques and Synthsonic, and shows that performance is often similar on highly imbalanced datasets. There are still questions on why and when oversampling is beneficial, but these might be answered in future studies.  