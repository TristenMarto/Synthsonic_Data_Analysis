\lhead{Literature Review}
This section discusses earlier work on alternative oversampling methods compared to SMOTE. When SMOTE was introduced in 2002, it proved to be a successful way to increase sensitivity to the minority class~\cite{Chawla2002SMOTE:Technique}. During the years after its publication, many alternatives were introduced such as ADASYN~\cite{He2008ADASYN:Learning} and Borderline-SMOTE~\cite{Han2005Borderline-SMOTE:Learning}. However, all oversamplers still relied on generating linear combinations from the samples in the minority class, but changed either which points were selected or how these were combined. 


\section{Generative Adversarial Networks}
Then Goodfellow et al. introduced a novel way of oversampling using a Generative Adversarial Network~\cite{Goodfellow2014GenerativeNets}. This deep learning method consists of a generative model $G$ which captures the data's distribution, and a discriminative model $D$ which estimates if a generated sample comes from the training data instead of $G$\footnote{Detailed description of the architecture of GANs are omitted in this thesis as it is not relevant to Synthsonic}. This approach is now used for synthesizing video and images which are indistinguishable from their real counterparts. This led to GAN adaptations such as MedGAN~\cite{Armanious2018MedGAN:GANs}, aiding medical image analysis and image translation, and VeeGAN~\cite{Srivastava2017VEEGAN:Learning}. The latter put more emphasis on the training method which could replicate the distribution of the dataset more accurately. While progression was being made, there was still an issue. The reason that GANs work so well on images and video is that the data is in a continuous-domain, these models still struggled when dealing with mixed distributions or discrete samples according to Camino et. al in 2020~\cite{Camino2020OversamplingEffort}. Their study showed that the improvements per performance metric are often significant when ranking the methods, but that the improvement in absolute terms is minor, also compared to the extra effort. Despite this, there was still a clear potential for data synthesis. 

\section{precursor of Synthsonic}
An article which sparked the idea for Synthsonic described how to use a Conditional GAN for modelling tabular data~\cite{Xu2019ModelingGAN}. Xu et al. were one of the first to apply a GAN to tabular data which contained both continuous and discrete features. While other articles were mainly focused on the -validity- of replicated images and videos, this article shifted the focus on being able to replicate a dataset instead. In other words, replicating data became a more important metric than replicating an image. However, using generative models 

Bayesian Networks on the other hand are proven to be effective for discrete features, two well performing models which are mentioned in literature are PrivBN~\cite{Zhang2014PrivBayes} and CLBN~\cite{Chow1968ApproximatingTrees}. The latter even dating back to 1968, showing its use was proven a long time ago. 

\section{Relevant study}
In 2019, Kovacs' published an empirical study where 85 oversamplers were tested on 104 datasets~\cite{Kovacs2019AnDatasets}. To date, there does not seem to be a study with a similar scale of approach. In comparison, the original SMOTE article used 9 datasets and ADASYN used 6 datasets. In theory, selecting fewer datasets can lead to skewed results when the oversampler is more suited to the chosen datasets. The approach of Kovacs is therefore a baseline in ranking SMOTE-based oversampling techniques. One issue with the study that the 104 datasets are not all unique. Some datasets are originally a multi-class classification problem, but the study only performed binary classification. To do this, multi class datasets were split on a one-vs-all basis, combining other labels to create an artificial imbalanced dataset. This creates many small datasets, some with around 100 total samples, where there are very few samples in the minority class to use for model training. The study also focused on SMOTE-based oversamplers only and did not include any 

In summary, most SMOTE-based oversamplers rely on a combination of both oversampling and undersampling to achieve an optimal performance. So far there has not been a method which can deliver a significant improvement when used as an only solution. GANs and Bayesian Networks provide an alternative but have their own drawbacks as well; GANs perform very well on continuous data, but are difficult to train and struggle with discrete features. There is still an ongoing search for a method which can reliably synthesize tabular data that contains both continuous and discrete features. Synthsonic aims to be a state of the art solution which can satisfy these conditions for a one step oversampling solution. While the comparison between SMOTE-based oversamplers has already been made, there is no study yet which tested generative models in a similar fashion. Camino et al.'s critical view on oversampling compared four SMOTE variants with four GANs, but was limited to two datasets. Combining these points, this thesis studies the effectiveness of Synthsonic as a probabilistic oversampling technique and compares this to popular SMOTE techniques.