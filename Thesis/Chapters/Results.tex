\lhead{\emph{Results}}

This chapter discusses about the results from the experiment with different SMOTE variants. 

10 oversamplers, including Synthsonic, were used in classifying 27 imbalanced datasets shown earlier in table~\ref{tab:df_info}. Due to the large amount of results, it is not feasible to discuss all details of oversampling. For comparison, the average results are shown for all datasets, but also per dataset type. The datasets are separated based on the number of categorical and numerical features in that dataset.

\section{Ranking of oversamplers}
In order to create a fair ranking over all datasets, we have taken the best performance per metric per oversampler. Table~\ref{tab:ranking} overview of the performance over various datasets with different characteristics. The first assumption is that the base classifier without oversampling should perform the worst out of all on most metrics. The exception is precision, which is expected to be higher when there is a high amount of samples in the majority class. 

\begin{table}[ht]
\centering
    \resizebox{\textwidth}{!}{
    \begin{tabular}{llrlrlrlrlrlr}
    \toprule
    {rank} &        Oversampler &  balanced\_accuracy &        Oversampler &    G\_mean &        Oversampler &        f1 &        Oversampler &  precision &        Oversampler &    recall &        Oversampler &    pr\_auc \\
    \midrule
    1  &             ADASYN &           0.798285 &             ADASYN &  0.729639 &           SVMSMOTE &  0.626186 &     NoOversampling &   0.699163 &             ADASYN &  0.614653 &         synthsonic &  0.649430 \\
    2  &              SMOTE &           0.797884 &              SMOTE &  0.729364 &             ADASYN &  0.623797 &  polynom\_fit\_SMOTE &   0.693186 &         synthsonic &  0.614159 &           SVMSMOTE &  0.649420 \\
    3  &         synthsonic &           0.797308 &         synthsonic &  0.726812 &              SMOTE &  0.621968 &  RandomOversampler &   0.686230 &              SMOTE &  0.614040 &             ADASYN &  0.649238 \\
    4  &           SVMSMOTE &           0.796564 &  RandomOversampler &  0.726309 &       Random\_SMOTE &  0.621696 &           SVMSMOTE &   0.681582 &  RandomOversampler &  0.613770 &  RandomOversampler &  0.648616 \\
    5  &  RandomOversampler &           0.796323 &       Random\_SMOTE &  0.725619 &    BorderlineSMOTE &  0.620457 &       Random\_SMOTE &   0.679765 &       Random\_SMOTE &  0.609360 &  polynom\_fit\_SMOTE &  0.647145 \\
    6  &       Random\_SMOTE &           0.795903 &           SVMSMOTE &  0.724931 &  RandomOversampler &  0.620094 &             ADASYN &   0.678240 &           SVMSMOTE &  0.608782 &              SMOTE &  0.647125 \\
    7  &    BorderlineSMOTE &           0.794202 &    BorderlineSMOTE &  0.724181 &         synthsonic &  0.614133 &    BorderlineSMOTE &   0.675135 &    BorderlineSMOTE &  0.605111 &       Random\_SMOTE &  0.645629 \\
    8  &  polynom\_fit\_SMOTE &           0.781970 &  polynom\_fit\_SMOTE &  0.697985 &  polynom\_fit\_SMOTE &  0.606298 &         synthsonic &   0.671432 &  polynom\_fit\_SMOTE &  0.576800 &    BorderlineSMOTE &  0.642862 \\
    9  &            SMOTENC &           0.768076 &            SMOTENC &  0.693449 &     NoOversampling &  0.580367 &              SMOTE &   0.670155 &            SMOTENC &  0.564887 &     NoOversampling &  0.641915 \\
    10 &     NoOversampling &           0.761715 &     NoOversampling &  0.653643 &            SMOTENC &  0.555265 &            SMOTENC &   0.582476 &     NoOversampling &  0.531739 &            SMOTENC &  0.571079 \\
    \bottomrule
    \end{tabular}}
\caption{A ranking of oversamplers based on their average score of all datasets}
\label{tab:ranking}
\end{table}

Next we can see from figure~\ref{fig:Total} that No oversampling scores the lowest on all metrics, in accordance with our predictions. 

\begin{figure}[htp]
\centering
    \includesvg[width=.45\textwidth]{../Plots/Total/total_balanced_accuracy.svg}\quad
    \includesvg[width=.45\textwidth]{../Plots/Total/total_G_mean.svg}
    \medskip
    \includesvg[width=.45\textwidth]{../Plots/Total/total_f1.svg} \quad
    \includesvg[width=.45\textwidth]{../Plots/Total/total_pr_auc.svg}
    \medskip
    \includesvg[width=.45\textwidth]{../Plots/Total/total_precision.svg}\quad
    \includesvg[width=.45\textwidth]{../Plots/Total/total_recall.svg}
\caption{Average metrics scores per oversampler on all datasets. All scores range from 0 (worst) to 1 (best).}
\label{fig:Total}
\end{figure}

\section{Numerical datasets}
The first subcategory of datasets are the ones with either only numerical features or a majority of them. This subset contains 17 datasets, the majority of the total 27. Regular SMOTE techniques are expected to perform better here as their techniques require continuous features to work. Figure~\ref{fig:Numerical}. Again ADASYN scores well on balanced accuracy and Geometric mean 

\begin{figure}[htp]
\centering
    \includesvg[width=.45\textwidth]{../Plots/Numerical/Numerical_balanced_accuracy.svg}\quad
    \includesvg[width=.45\textwidth]{../Plots/Numerical/Numerical_G_mean.svg}
    \medskip
    \includesvg[width=.45\textwidth]{../Plots/Numerical/Numerical_f1.svg} \quad
    \includesvg[width=.45\textwidth]{../Plots/Numerical/Numerical_pr_auc.svg}
    \medskip
    \includesvg[width=.45\textwidth]{../Plots/Numerical/Numerical_precision.svg}\quad
    \includesvg[width=.45\textwidth]{../Plots/Numerical/Numerical_recall.svg}
\caption{Average metrics scores per oversampler on datasets containing numerical features. All scores range from 0 (worst) to 1 (best).}
\label{fig:Numerical}
\end{figure}

\section{Categorical datasets}
The second subcategory of datasets are the ones with either exclusively or a large majority of categorical datasets. This includes nine of the total 27 datasets. Results are shown in figure~\ref{fig:Categorical}, after selecting the highest score per dataset  The assumption was that methods such as Synthsonic or ADASYN, which don't rely on a nearest neighbour principle, to perform better on this subset.

\begin{figure}[htp]
\centering
    \includesvg[width=.45\textwidth]{../Plots/Categorical/Categorical_balanced_accuracy.svg}\quad
    \includesvg[width=.45\textwidth]{../Plots/Categorical/Categorical_G_mean.svg}
    \medskip
    \includesvg[width=.45\textwidth]{../Plots/Categorical/Categorical_f1.svg} \quad
    \includesvg[width=.45\textwidth]{../Plots/Categorical/Categorical_pr_auc.svg}
    \medskip
    \includesvg[width=.45\textwidth]{../Plots/Categorical/Categorical_precision.svg}\quad
    \includesvg[width=.45\textwidth]{../Plots/Categorical/Categorical_recall.svg}
\caption{Average metrics scores per oversampler on datasets containing categorical features. All scores range from 0 (worst) to 1 (best).}
\label{fig:Categorical}
\end{figure}

The first observation is that SMOTE-NC performs poorly on these datasets, even scoring the lowest on F1-score, PR AUC and precision. Note that SMOTE-NC does not work on exclusively categorical features, and therefore only was used on three instead of nine datasets. Despite this, we want to portray how oversamplers perform in a wide variety of situations and try to find an overall best oversampler. For this reason the results of SMOTE-NC are included.

Comparing these results to those of the total datasets, we can see that Synthsonic scores higher on balanced accuracy and Geometric mean when compared to the total results. This means that Synthsonic is able to discern true positives and true negatives better due to oversampling. This is also reflected in the highest score in recall on categorical datasets, but when comparing to the total results we see a higher drop in precision. 

Contrary to the total results, there is a smaller trade-off between precision and recall.

\section{Mixed datasets}
Here figure~\ref{fig:mixed}

\begin{figure}[htp]
\centering
    \includesvg[width=.45\textwidth]{../Plots/Mixed/Mixed_balanced_accuracy.svg}\quad
    \includesvg[width=.45\textwidth]{../Plots/Mixed/Mixed_G_mean.svg}
    \medskip
    \includesvg[width=.45\textwidth]{../Plots/Mixed/Mixed_f1.svg} \quad
    \includesvg[width=.45\textwidth]{../Plots/Mixed/Mixed_pr_auc.svg}
    \medskip
    \includesvg[width=.45\textwidth]{../Plots/Mixed/Mixed_precision.svg}\quad
    \includesvg[width=.45\textwidth]{../Plots/Mixed/Mixed_recall.svg}
\caption{Average metrics scores per oversampler on datasets containing a mix of numerical and categorical features. All scores range from 0 (worst) to 1 (best).}
\label{fig:mixed}
\end{figure}


