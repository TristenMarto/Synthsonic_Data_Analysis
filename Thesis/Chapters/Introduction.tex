\lhead{\emph{Introduction}}

Imbalanced learning is a term used to describe certain classification problems. In a classification problem the goal is to train a classifier to distinguish samples from different classes. In practice this could mean a classifier which determines if a patient has a disease or not, or more finance related, whether a transaction is fraudulent or not.

The imbalance implies that there is a mismatch between the sizes of the classes, something that is very common in real data sets. In the example of fraud detection: fraud transactions only make up a minute amount of all transactions. This leads to a problem when training a classifier. A classifier assumes that the classes are (roughly) equal in size and will create a model which distinguishes between the two classes. When one class significantly outweighs the other and the decision boundary becomes unclear. As a result, the classifier will favour the majority class and 

However, most classifiers will still appear to score well even 

\section{Related work}

oversamplers